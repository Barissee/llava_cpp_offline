# llava-cpp-offline ğŸ§ ğŸ–¼ï¸  
Offline image analysis with LLaVA 1.6 + Visual Studio build  
by **Baris**

This project shows how to compile and run LLaVA locally on Windows â€“ without any API, without cloud, and without Python dependencies.

## ğŸ”¥ Features

- Fully offline LLaVA Vision model
- Compiled llama-llava-cli (.exe)
- GGUF model support
- GUI + image understanding
- Python wrapper via `llava_cpp.py`

## ğŸ“¦ Repository contents

- `llama-llava-cli.exe` â†’ compiled CLI interface for LLaVA
- `llava_cpp.py` â†’ Python wrapper for CLI calls
- `example_usage.py` â†’ test script
- `models/` â†’ place your LLaVA + MMProj models here
- `screenshots/` â†’ test images

## ğŸ§  Download models

ğŸ‘‰ Main model:  
https://huggingface.co/liuhaotian/llava-v1.6-mistral-7b-GGUF

ğŸ‘‰ MMProj encoder:  
https://huggingface.co/liuhaotian/llava-v1.6-mistral-7b-GGUF/tree/main/mmproj

Put both files inside the `models/` folder:

## ğŸ Python example

```python
from llava_cpp import analyze_image

response = analyze_image("screenshots/test_gui.png")
print("Response:", response)

